# NLP: Document Classification Group Project

Internship Group Project for classification of 20_newsgroup data NLP. 

The data 20_newsgroups_new.tar.gz contains the latest data already cleaned. From there, it could be further cleaned if required. This is not necessarily used, sometimes we just fetch directly from sklearn. 

Internal note: One thing to note on the printing of pandas DataFrame. For text we output quite a long list of words, but that's quite unique in a specific conda environment. For a usual conda environment, that doesn't exist. One isn't sure why is that but that's the case. One guesses that's something to do with fastai library but one cannot prove it without proper experimentation. 

## Edit 23 November 2021
Since the data is very big and one doesn't have lots of GIT LFS storage available, one is sharing the pretrained-encoder and trained-models through [this link](https://mega.nz/folder/B6xiUKAA#bLoIPShzjCOeQs1DTM-RGg).

## Edit 25 November 2021
Those with pdf upload the pdfs (and ipynb if asked, check your submission). For Week 10 upload `EDA.ipynb`. For Week 12 upload `advanced_model.ipynb`. 


## Acknowledgments

Ken Lang is credited by the source for collecting this data. The source of the data files is here:
http://qwone.com/~jason/20Newsgroups/

## Inspiration
This dataset text can be used to classify text documents
 
